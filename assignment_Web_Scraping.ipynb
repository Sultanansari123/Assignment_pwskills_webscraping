{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9d0042-ac7e-4125-b58a-16f6f7a75a16",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab7df0-51cf-475a-b9d8-0aabff58f890",
   "metadata": {},
   "source": [
    "Ans1-Web scraping is he automated extraction of data from  website.It is used to gathered information for various purposes such as data analysis,research and business intelligence.Three area where web scraping is commonly used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8311ca3-38bf-4b5f-908c-2c4208cf8fbc",
   "metadata": {},
   "source": [
    "Business and Market Research: Companies use web scraping to collect data on competitors, market trends, and consumer sentiments.\n",
    "Price Comparison: E-commerce platforms use web scraping to monitor and compare prices of products across different websites.\n",
    "Content Aggregation: News websites and content aggregators use web scraping to gather and display information from various sources on a single platform.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d5df0-8e2c-4d0c-b82c-97a4ed2cefef",
   "metadata": {},
   "source": [
    "Ans2-\n",
    "Web scraping can be done using various methods, including:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073cea95-f8d0-46bc-968f-ec04a83ab1d9",
   "metadata": {},
   "source": [
    "1->HTML Parsing: Parsing the HTML structure of a webpage to extract relevant data using libraries like BeautifulSoup in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e134c8-5be0-45b0-a3a8-0b8691125588",
   "metadata": {},
   "source": [
    "2->Regular Expressions: Employing regular expressions to match and extract patterns in the raw HTML source code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda7775-25c6-4160-b273-96f49f6186bc",
   "metadata": {},
   "source": [
    "3->APIs: Accessing data through APIs (Application Programming Interfaces) provided by websites, when available, as a more structured and ethical way to obtain information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a08166-6d2d-4c4f-8f9d-981abbcc908d",
   "metadata": {},
   "source": [
    "3->Headless Browsing: Using automated browsers like Selenium to simulate human interaction with a webpage, allowing dynamic content to load before scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b0b97-12a3-4efb-a183-cfb8facea5c5",
   "metadata": {},
   "source": [
    "4->Scrapy Framework: Utilizing web scraping frameworks like Scrapy, which provides a set of tools and conventions for building web scrapers efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f751cf-d925-47af-b537-81b8ccb18869",
   "metadata": {},
   "source": [
    "Ans3-\"Beautiful Soup.\" Beautiful Soup is a Python library used for web scraping purposes. It provides tools for pulling data out of HTML and XML files, making it easier to navigate and extract information from web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244503bb-cff3-4fb1-9736-abfae553cf16",
   "metadata": {},
   "source": [
    "Ans4-\n",
    "Flask is commonly used in web scraping projects for several reasons:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca627999-acb5-4433-9e68-aee8a495e12d",
   "metadata": {},
   "source": [
    "->Web application development-In a web scraping project, Flask can be used to create a user interface for displaying scraped data or controlling the scraping process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3201f7-23c2-4ba8-af25-5256119367e4",
   "metadata": {},
   "source": [
    "->API Integration: Flask allows easy integration of APIs. In a web scraping project, this can be valuable for receiving and processing data from multiple sources or presenting the scraped data through a RESTful API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b609f73b-3dc1-4f71-b2ae-be57f4e07159",
   "metadata": {},
   "source": [
    "->Automation and Control: Flask enables the creation of web interfaces that provide control over the web scraping process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e594038-c930-4501-b06f-9e30bd43b974",
   "metadata": {},
   "source": [
    "->Data Presentation: Flask helps in presenting the scraped data in a structured and accessible manner.The scraped information can be displayed on a web page, making it convenient for users to interact with and analyze the gathered data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ba1dc-ab5d-4c7a-aeda-b5c774be6a84",
   "metadata": {},
   "source": [
    "Ans5-In a web scraping project hosted on AWS, several services might be used, depending on the project requirements. Here are a few AWS services commonly utilized:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9da6b-be54-4551-a73d-7f5420c0ef8f",
   "metadata": {},
   "source": [
    "Amazon EC2 (Elastic Compute Cloud): EC2 provides virtual servers in the cloud, offering scalable compute capacity. It can be used to host the web scraping application, manage databases, and execute scraping tasks.\n",
    "\n",
    "Amazon S3 (Simple Storage Service): S3 is a scalable object storage service, suitable for storing and retrieving large amounts of data. In a web scraping project, S3 can be used to store scraped data, logs, or any other files generated during the scraping process.\n",
    "\n",
    "AWS Lambda: Lambda is a serverless compute service that allows running code without provisioning or managing servers. It can be used for automating periodic scraping tasks, triggered by events or schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2df05-78ec-41a5-aaf9-6e3473e39d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
